{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Users/sainikhithamadduri/Desktop/DAEN 690 Project/strategy_uncleaned.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text         label\n",
      "0     [$5, million, milestones, tied, natera's, supp...      strategy\n",
      "1     [,, growth, expected, remain, elevated, 2018,,...      strategy\n",
      "2     [,, uk, canada., remainder, investments, direc...      strategy\n",
      "3     [..., question, strategic, initiative, slides,...      strategy\n",
      "4     [\\\\\", sustainability, continues, increasingly,...      strategy\n",
      "5     [0, high, growth, markets, 5g,, smart, iot, ap...      strategy\n",
      "6     [00), chairman,, mean,, very, hands-on,, very,...      strategy\n",
      "7     [00), strategic, plan, strengthens, business, ...      strategy\n",
      "8     [01), period,, interested, get, feedback, stra...      strategy\n",
      "9     [015, per, gallon, lower., reflects, strategy,...      strategy\n",
      "10    [05, eps, per, quarter, first, half, 2018., pa...      strategy\n",
      "11    [05), evaluating, requirements, expectations, ...      strategy\n",
      "12    [06, impact, earnings, per, share, next, two, ...      strategy\n",
      "13    [07), 2018,, parallel, executing, last, year, ...      strategy\n",
      "14    [07), margins., furthermore,, execution, strat...      strategy\n",
      "15    [09)., lastly,, strategy, debt, still, capital...      strategy\n",
      "16    [1, billion, range., expect, gross, operating,...      strategy\n",
      "17    [1, billion., despite, historical, level, cata...      strategy\n",
      "18    [1, per, share,, underscoring, group's, confid...      strategy\n",
      "19    [1%, fourth, quarter,, percentage, growth, exp...      strategy\n",
      "20    [1%, national, level., heading, new, year,, st...      strategy\n",
      "21    [1%,, adjusted, earnings, per, preferred, shar...      strategy\n",
      "22    [10, fourth, quarter, 2016., higher, non-fuel,...      strategy\n",
      "23    [10), so,, contribution, can't, level, seen, p...      strategy\n",
      "24    [10,, reflect, tax, reform, factors, discussed...      strategy\n",
      "25    [11, per, quarter., base,, goal, grow, core, e...      strategy\n",
      "26    [11), closer, $200, million, moving, forward.,...      strategy\n",
      "27    [11)., so,, think, we're, focused, main, playe...      strategy\n",
      "28    [13, per, share, annual, outlay, approximately...      strategy\n",
      "29    [13), generally, not, pursue, max, proceed, lo...      strategy\n",
      "...                                                 ...           ...\n",
      "3202  [look,, don't, think, we're, ready, introduce,...  not relevant\n",
      "3203  [so,, since, we've, that,, we're, pretty, reas...  not relevant\n",
      "3204  [simply, gotten, much, harder, walk, big, bran...  not relevant\n",
      "3205  [we're, going, pros, cons, want, approach, tha...  not relevant\n",
      "3206  [proposed, law, would, roll, back, medicaid, e...  not relevant\n",
      "3207  [budget,, expect, resume, year-over-year, prod...  not relevant\n",
      "3208  [delta, working, capital, piece,, balance, she...  not relevant\n",
      "3209  [we're, pleased, final, 2017, number., feel, c...  not relevant\n",
      "3210  [among, better, known, luxury, gran, hotel, ma...  not relevant\n",
      "3211  [want, conversation, friend,, certain, expecta...  not relevant\n",
      "3212  [fitch's, rating, action, reflects, belief, te...  not relevant\n",
      "3213  [addition,, paypal's, profit, margin, per, tra...  not relevant\n",
      "3214  [actavis, filed, suit, more, three, years, ago...  not relevant\n",
      "3215  [patent, approved, within, area, 3d-based, ass...  not relevant\n",
      "3216  [american, said, provides, travel, federal, go...  not relevant\n",
      "3217  [outlooks, 2018,, see, tier, slide., deliver, ...  not relevant\n",
      "3218  [think, adds, modularized, design, process, el...  not relevant\n",
      "3219  [acquiflow,, value-added, reseller,, selects, ...  not relevant\n",
      "3220  [vmware, nsx, portfolio,, ability, deliver, pe...  not relevant\n",
      "3221  [com/events, oppenheimer, 27(th), annual, heal...  not relevant\n",
      "3222  [point, number, three, is,, fundamentally,, gr...  not relevant\n",
      "3223  [fda, process, accelerated, approval., said, v...  not relevant\n",
      "3224  [yeah,, attitude, approach, philosophy, not, c...  not relevant\n",
      "3225  [combined, market, capitalization, five, valua...  not relevant\n",
      "3226  [market,, manage, differently., feel, confiden...  not relevant\n",
      "3227  [dave,, add, think, partner, some, sophisticat...  not relevant\n",
      "3228  [delve, intentionally, domain, help, us, under...  not relevant\n",
      "3229  [homeownership, rate, fell, fourth, quarter,, ...  not relevant\n",
      "3230  [wildly, popular, velocityshares, daily, inver...  not relevant\n",
      "3231  [14%, 2,businesses, surveyed, financial, condu...  not relevant\n",
      "\n",
      "[3232 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#convert to lower case and split the string\n",
    "df['text'] = df['text'].str.lower().str.split()\n",
    "#Remove stop words except few which adds weightage to sentiment\n",
    "stop = set(stopwords.words('english')) - {'above','against','couldn',\"aren't\",\"didn\",\"didn't\",\"dosen't\",\"don't\",\"hadn't\",\n",
    "                                    \"hasn't\",\"haven't\",\"isn't\",\"mightn't\",\"more\",\"mustn't\",\"needn't\",\"no\",\"not\",\n",
    "                                    \"out\",\"shan't\",\"shouldn't\",\"some\",\"very\",\"wasn't\",\"weren't\",\"won't\",\"wouldn't\"} \n",
    "            \n",
    "df['text'] = df['text'].apply(lambda x: [item for item in x if item not in stop])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                   text         label\n",
      "0     $5 million milestones tied natera's support ac...      strategy\n",
      "1     , growth expected remain elevated 2018, driven...      strategy\n",
      "2     , uk canada. remainder investments directed st...      strategy\n",
      "3     ... question strategic initiative slides, stre...      strategy\n",
      "4     \\\\\" sustainability continues increasingly impo...      strategy\n",
      "5     0 high growth markets 5g, smart iot applicatio...      strategy\n",
      "6     00) chairman, mean, very hands-on, very active...      strategy\n",
      "7     00) strategic plan strengthens business model ...      strategy\n",
      "8     01) period, interested get feedback strategy a...      strategy\n",
      "9     015 per gallon lower. reflects strategy win ne...      strategy\n",
      "10    05 eps per quarter first half 2018. pass call ...      strategy\n",
      "11    05) evaluating requirements expectations new c...      strategy\n",
      "12    06 impact earnings per share next two years. h...      strategy\n",
      "13    07) 2018, parallel executing last year strateg...      strategy\n",
      "14    07) margins. furthermore, execution strategic ...      strategy\n",
      "15    09). lastly, strategy debt still capital manag...      strategy\n",
      "16    1 billion range. expect gross operating margin...      strategy\n",
      "17    1 billion. despite historical level catastroph...      strategy\n",
      "18    1 per share, underscoring group's confidence c...      strategy\n",
      "19    1% fourth quarter, percentage growth experienc...      strategy\n",
      "20    1% national level. heading new year, strategic...      strategy\n",
      "21    1%, adjusted earnings per preferred share line...      strategy\n",
      "22    10 fourth quarter 2016. higher non-fuel o&m pa...      strategy\n",
      "23    10) so, contribution can't level seen past. cl...      strategy\n",
      "24    10, reflect tax reform factors discussed today...      strategy\n",
      "25    11 per quarter. base, goal grow core earnings,...      strategy\n",
      "26    11) closer $200 million moving forward. compet...      strategy\n",
      "27    11). so, think we're focused main players alig...      strategy\n",
      "28    13 per share annual outlay approximately $75 m...      strategy\n",
      "29    13) generally not pursue max proceed loans. st...      strategy\n",
      "...                                                 ...           ...\n",
      "3202  look, don't think we're ready introduce new pr...  not relevant\n",
      "3203  so, since we've that, we're pretty reasonably ...  not relevant\n",
      "3204  simply gotten much harder walk big brands' age...  not relevant\n",
      "3205  we're going pros cons want approach that. impo...  not relevant\n",
      "3206  proposed law would roll back medicaid expansio...  not relevant\n",
      "3207  budget, expect resume year-over-year productio...  not relevant\n",
      "3208  delta working capital piece, balance sheet abs...  not relevant\n",
      "3209  we're pleased final 2017 number. feel confiden...  not relevant\n",
      "3210  among better known luxury gran hotel manzana k...  not relevant\n",
      "3211  want conversation friend, certain expectation ...  not relevant\n",
      "3212  fitch's rating action reflects belief teva fac...  not relevant\n",
      "3213  addition, paypal's profit margin per transacti...  not relevant\n",
      "3214  actavis filed suit more three years ago commer...  not relevant\n",
      "3215  patent approved within area 3d-based assessmen...  not relevant\n",
      "3216  american said provides travel federal governme...  not relevant\n",
      "3217  outlooks 2018, see tier slide. deliver f3-r st...  not relevant\n",
      "3218  think adds modularized design process elements...  not relevant\n",
      "3219  acquiflow, value-added reseller, selects helio...  not relevant\n",
      "3220  vmware nsx portfolio, ability deliver pervasiv...  not relevant\n",
      "3221  com/events oppenheimer 27(th) annual healthcar...  not relevant\n",
      "3222  point number three is, fundamentally, growing ...  not relevant\n",
      "3223  fda process accelerated approval. said vital t...  not relevant\n",
      "3224  yeah, attitude approach philosophy not changed...  not relevant\n",
      "3225  combined market capitalization five valuable c...  not relevant\n",
      "3226  market, manage differently. feel confident sec...  not relevant\n",
      "3227  dave, add think partner some sophisticated too...  not relevant\n",
      "3228  delve intentionally domain help us understand ...  not relevant\n",
      "3229  homeownership rate fell fourth quarter, frustr...  not relevant\n",
      "3230  wildly popular velocityshares daily inverse vi...  not relevant\n",
      "3231  14% 2,businesses surveyed financial conduct au...  not relevant\n",
      "\n",
      "[3232 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "#Join the splitted words\n",
    "df['text'] = df['text'].apply(' '.join)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strategic', 1447),\n",
       " ('strategy', 864),\n",
       " ('us', 809),\n",
       " ('growth', 716),\n",
       " (\"we're\", 692),\n",
       " ('more', 684),\n",
       " ('continue', 598),\n",
       " ('business', 566),\n",
       " ('new', 537),\n",
       " ('very', 461),\n",
       " ('think', 452),\n",
       " ('also', 451),\n",
       " ('plan', 436),\n",
       " ('some', 430),\n",
       " (\"we've\", 419),\n",
       " ('year', 413),\n",
       " ('not', 382),\n",
       " ('financial', 375),\n",
       " ('going', 354),\n",
       " ('so,', 347),\n",
       " ('capital', 346),\n",
       " ('market', 334),\n",
       " ('strong', 326),\n",
       " ('long-term', 317),\n",
       " ('initiatives', 310),\n",
       " ('million', 307),\n",
       " ('one', 301),\n",
       " ('quarter', 296),\n",
       " ('like', 290),\n",
       " ('well', 288)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Top 30 most common words\n",
    "from collections import Counter\n",
    "\n",
    "subject_word_bag = df.text.apply(lambda t: t.lower() + \" \").sum()\n",
    "\n",
    "Counter(subject_word_bag.split()).most_common()[:30]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#word split \n",
    "subject_words = [word for word in subject_word_bag.split() if word.lower() not in stop]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(('strategic', 'plan'), 0.002130738567255875)\n",
      "(('strategic', 'initiatives'), 0.0020952262578016103)\n",
      "(('allows', 'us'), 0.00205083587098378)\n",
      "(('strategic', 'priorities'), 0.0018732743237124569)\n",
      "(('fourth', 'quarter'), 0.0009588323552651438)\n",
      "(('allow', 'us'), 0.0009410762005380114)\n",
      "(('strategic', 'plan.'), 0.0008700515816294824)\n",
      "(('cash', 'flow'), 0.0008256611948116516)\n",
      "(('strategic', 'initiatives.'), 0.0007368804211759901)\n",
      "((\"we're\", 'going'), 0.0007102461890852917)\n",
      "(('strategic', 'priorities.'), 0.0006924900343581594)\n",
      "((\"i'd\", 'like'), 0.0006747338796310271)\n",
      "(('balance', 'sheet'), 0.0006569777249038948)\n",
      "(('key', 'strategic'), 0.0006125873380860641)\n",
      "(('strategic', 'plan,'), 0.0005859531059953656)\n",
      "(('feel', 'confident'), 0.0005681969512682333)\n",
      "(('strategic', 'initiatives,'), 0.0005681969512682333)\n",
      "(('little', 'bit'), 0.0005593188739046672)\n",
      "(('would', 'like'), 0.0005415627191775349)\n",
      "(('turn', 'call'), 0.0005149284870868365)\n"
     ]
    }
   ],
   "source": [
    "#Collocation \n",
    "\n",
    "from nltk import collocations\n",
    "bigram_measures = collocations.BigramAssocMeasures()\n",
    "bigram_finder = collocations.BigramCollocationFinder.from_words(subject_words)\n",
    "\n",
    "bigram_finder.apply_freq_filter(20)\n",
    "for bigram in bigram_finder.score_ngrams(bigram_measures.raw_freq)[:20]:\n",
    "    print(bigram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No.of words in each sentence\n",
    "\n",
    "# df['word_count'] = df['text'].apply(lambda x: len(str(x).split(\" \")))\n",
    "# df[['text','word_count']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Average words per sentence\n",
    "\n",
    "# def avg_word(stext):\n",
    "#   words = text.split()\n",
    "#   return (sum(len(word) for word in words)/len(words))\n",
    "\n",
    "# df['avg_word'] = df['text'].apply(lambda x: avg_word(x))\n",
    "# df[['text','avg_word']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#No.of numerics in sentences\n",
    "\n",
    "# df['numerical data'] = df['text'].apply(lambda x: len([x for x in x.split() if x.isdigit()]))\n",
    "# df[['text','numerical data']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5 million milestones tied nateras support acti...\n",
       "1     growth expected remain elevated 2018 driven i...\n",
       "2     uk canada remainder investments directed stra...\n",
       "3     question strategic initiative slides stress f...\n",
       "4     sustainability continues increasingly importa...\n",
       "5    0 high growth markets 5g smart iot application...\n",
       "6    00 chairman mean very handson very active core...\n",
       "7    00 strategic plan strengthens business model p...\n",
       "8    01 period interested get feedback strategy ass...\n",
       "9    015 per gallon lower reflects strategy win new...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Removing punctuations\n",
    "\n",
    "df['text'] = df['text'].str.replace('[^\\w\\s]','')\n",
    "df['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "strategic      1448\n",
      "strategy       1284\n",
      "growth          962\n",
      "us              901\n",
      "business        800\n",
      "year            761\n",
      "more            697\n",
      "were            694\n",
      "plan            687\n",
      "continue        608\n",
      "well            607\n",
      "2018            599\n",
      "new             540\n",
      "initiatives     503\n",
      "think           486\n",
      "very            484\n",
      "also            479\n",
      "2017            470\n",
      "quarter         435\n",
      "some            430\n",
      "market          428\n",
      "weve            419\n",
      "million         391\n",
      "not             391\n",
      "priorities      380\n",
      "capital         378\n",
      "financial       376\n",
      "company         364\n",
      "results         356\n",
      "going           354\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "#word frequency\n",
    "freq = pd.Series(' '.join(df['text']).split()).value_counts()[:30]\n",
    "print(freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Spelling correction\n",
    "# Minimum 20 mins to run\n",
    "# from textblob import TextBlob\n",
    "# df['Sentences'] = df['Sentences'].apply(lambda x: str(TextBlob(x).correct()))\n",
    "# df['Sentences'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5 million milestone tied nateras support activ...\n",
       "1    growth expected remain elevated 2018 driven in...\n",
       "2    uk canada remainder investment directed strate...\n",
       "3    question strategic initiative slide stress foc...\n",
       "4    sustainability continues increasingly importan...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Lemmatization\n",
    "from textblob import Word\n",
    "df['text'] = df['text'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "df['text'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('strategic', 1448),\n",
       " ('strategy', 1312),\n",
       " ('year', 1073),\n",
       " ('u', 970),\n",
       " ('growth', 962),\n",
       " ('business', 892),\n",
       " ('plan', 862),\n",
       " ('more', 697),\n",
       " ('were', 694),\n",
       " ('market', 662),\n",
       " ('well', 609),\n",
       " ('continue', 608),\n",
       " ('2018', 599),\n",
       " ('initiative', 592),\n",
       " ('new', 540),\n",
       " ('customer', 495),\n",
       " ('company', 493),\n",
       " ('think', 487),\n",
       " ('very', 484),\n",
       " ('also', 479),\n",
       " ('2017', 470),\n",
       " ('quarter', 469),\n",
       " ('result', 433),\n",
       " ('some', 430),\n",
       " ('weve', 419),\n",
       " ('priority', 409),\n",
       " ('product', 403),\n",
       " ('million', 397),\n",
       " ('not', 391),\n",
       " ('capital', 378),\n",
       " ('financial', 376),\n",
       " ('opportunity', 372),\n",
       " ('one', 361),\n",
       " ('going', 354),\n",
       " ('so', 351),\n",
       " ('investment', 341),\n",
       " ('strong', 340),\n",
       " ('longterm', 330),\n",
       " ('time', 321),\n",
       " ('like', 298)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Mostly frequently repeated words\n",
    "from collections import Counter\n",
    "\n",
    "subject_word_bag = df.text.apply(lambda t: t.lower() + \" \").sum()\n",
    "\n",
    "Counter(subject_word_bag.split()).most_common()[:40]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Strategy_cleaned')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Text sentiment\n",
    "df['sentiment'] = df['text'].apply(lambda x: TextBlob(x).sentiment[0] )\n",
    "df1 = df[['text','sentiment']]\n",
    "df1\n",
    "df1.to_csv('opportunity_sentiment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the text sentiment values\n",
    "senti = pd.read_csv(\"/Users/sainikhithamadduri/Desktop/DAEN 690 Project/oppur_sentiment.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count negative sentences\n",
    "neg_count = len(list(filter(lambda x: (x < 0), df['sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count positive sentences\n",
    "pos_count = len(list(filter(lambda x: (x > 0), df['sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count neutral sentences\n",
    "neu_count = len(list(filter(lambda x: (x == 0), df['sentiment'])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#count total no.of sentences\n",
    "total = len(senti.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of sentences:  3153\n",
      "Positive sentences:  2549\n",
      "Negative sentences:  390\n",
      "Neutral sentences:  293\n"
     ]
    }
   ],
   "source": [
    "#print pos, neg and neutral sentences\n",
    "print(\"Total number of sentences: \", total)\n",
    "print(\"Positive sentences: \", pos_count) \n",
    "print(\"Negative sentences: \", neg_count) \n",
    "print(\"Neutral sentences: \", neu_count) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
